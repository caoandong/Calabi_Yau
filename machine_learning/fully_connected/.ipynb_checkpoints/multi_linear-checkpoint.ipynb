{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data:  10100\n",
      "sample data:  [0, 1, 1]\n",
      "number of data:  1000\n",
      "number of parameters:  3\n",
      "number of test:  1000\n",
      "Beginning Training\n",
      "epoch:  1\n",
      "loss:  3.1031156\n",
      "loss:  7.9520044\n",
      "loss:  9.177099\n",
      "loss:  12.003052\n",
      "loss:  14.035508\n",
      "loss:  8.885265\n",
      "loss:  9.026624\n",
      "loss:  4.992687\n",
      "loss:  9.242185\n",
      "loss:  26.32302\n",
      "loss:  1.9487853\n",
      "loss:  6.0147943\n",
      "loss:  23.573664\n",
      "loss:  3.2422874\n",
      "loss:  7.05889\n",
      "loss:  4.739183\n",
      "loss:  10.82374\n",
      "loss:  3.471589\n",
      "loss:  7.0185413\n",
      "loss:  6.301442\n",
      "loss:  25.917585\n",
      "loss:  2.4931765\n",
      "loss:  5.97263\n",
      "loss:  15.561093\n",
      "loss:  12.069449\n",
      "loss:  20.573374\n",
      "loss:  3.9292612\n",
      "loss:  6.4307714\n",
      "loss:  8.255787\n",
      "loss:  4.9081564\n",
      "loss:  38.885517\n",
      "loss:  1.6573607\n",
      "loss:  2.7661383\n",
      "loss:  11.351982\n",
      "loss:  18.123781\n",
      "loss:  14.559143\n",
      "loss:  1.4899789\n",
      "loss:  42.973263\n",
      "loss:  7.304552\n",
      "loss:  10.019865\n",
      "loss:  8.877336\n",
      "loss:  3.2558935\n",
      "loss:  0.5282096\n",
      "loss:  5.084958\n",
      "loss:  53.775986\n",
      "loss:  1.5594122\n",
      "loss:  5.7328963\n",
      "loss:  11.339006\n",
      "loss:  9.561106\n",
      "loss:  4.8412266\n",
      "loss:  1.1080605\n",
      "loss:  8.437989\n",
      "loss:  98.00172\n",
      "loss:  5.919627\n",
      "loss:  1.6843587\n",
      "loss:  1.3752342\n",
      "loss:  6.3780613\n",
      "loss:  14.349873\n",
      "loss:  10.733508\n",
      "loss:  2.6129088\n",
      "loss:  3.0572872\n",
      "loss:  96.90554\n",
      "loss:  9.689693\n",
      "loss:  13.584476\n",
      "loss:  3.0645106\n",
      "loss:  1.6729659\n",
      "loss:  7.605645\n",
      "loss:  10.162215\n",
      "loss:  6.556885\n",
      "loss:  2.590607\n",
      "loss:  4.1125026\n",
      "loss:  108.51422\n",
      "loss:  8.167499\n",
      "loss:  3.833581\n",
      "loss:  1.5137916\n",
      "loss:  1.9994872\n",
      "loss:  7.58682\n",
      "loss:  9.128848\n",
      "loss:  4.730686\n",
      "loss:  1.2607151\n",
      "loss:  3.830061\n",
      "loss:  7.3771253\n",
      "loss:  123.803894\n",
      "loss:  4.682311\n",
      "loss:  0.91799426\n",
      "loss:  4.7891006\n",
      "loss:  14.993697\n",
      "loss:  23.297886\n",
      "loss:  16.230738\n",
      "loss:  3.2444851\n",
      "loss:  3.1623487\n",
      "loss:  15.834075\n",
      "loss:  17.85625\n",
      "loss:  6.8397617\n",
      "loss:  115.28604\n",
      "loss:  2.3118083\n",
      "loss:  3.5263014\n",
      "loss:  20.494429\n",
      "loss:  43.802906\n",
      "loss:  49.7538\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_param' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-05cbd698f2bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_vol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'sample data: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_vol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-05cbd698f2bc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, vol)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# Train one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_parameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_volume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_vol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0meval_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_parameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_volume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_vol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_param' is not defined"
     ]
    }
   ],
   "source": [
    "# Input: parametrized heights\n",
    "# Output: volume\n",
    "\n",
    "def placeholder_inputs(batch_size, num_param):\n",
    "    param_pl = tf.placeholder(name=\"input_param\", dtype=tf.float32, shape=(batch_size, num_param))\n",
    "    vol_pl = tf.placeholder(name=\"input_vol\", dtype=tf.float32, shape=(batch_size))\n",
    "    \n",
    "    return param_pl, vol_pl\n",
    "\n",
    "def load_input(train_path):\n",
    "    train = open(train_path, 'r')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for line in train:\n",
    "        data = eval(line)\n",
    "        if data[1] > 0:\n",
    "            train_x.append(data[0])\n",
    "            inv_vol = 1/data[1]\n",
    "            train_y.append(inv_vol)\n",
    "    print ('Number of data: ', len(train_x))\n",
    "    \n",
    "    return train_x, train_y\n",
    "\n",
    "def fl_linear(param, batch_size, num_param):\n",
    "    with tf.variable_scope(\"fl_linear\"):\n",
    "        input_param = tf.placeholder(name=\"input_param\", dtype=tf.float32, shape=(batch_size, num_param))\n",
    "        input_vol = tf.placeholder(name=\"input_vol\", dtype=tf.float32, shape=(batch_size))\n",
    "        # Linear activation\n",
    "        net = tf.fully_connected(1, activation_fn=None, scope='fc1')\n",
    "    \n",
    "    return net\n",
    "\n",
    "def mat_mul(param, batch_size, num_param):\n",
    "    with tf.variable_scope(\"mat_mul\"):\n",
    "        input_parameter = tf.placeholder(name=\"input_parameter\", dtype=tf.float32, shape=(batch_size, num_param))\n",
    "        input_volume = tf.placeholder(name=\"input_volume\", dtype=tf.float32, shape=(batch_size))\n",
    "        W = tf.Variable(tf.random_normal([num_param, 1], dtype=tf.float32), name=\"W\")\n",
    "        b = tf.Variable(tf.zeros([batch_size, 1], dtype=tf.float32), name=\"b\")\n",
    "        y = tf.add(tf.matmul(input_parameter, W), b)\n",
    "        cost_op = tf.reduce_mean(tf.pow(y-input_volume, 2))\n",
    "\n",
    "    return y, cost_op, input_parameter, input_volume\n",
    "\n",
    "def train(data, vol):\n",
    "    \n",
    "    input_data = data[0:1000]\n",
    "    input_vol = vol[0:1000]\n",
    "    \n",
    "    test_data = data[1000:2000]\n",
    "    test_vol = vol[1000:2000]\n",
    "    \n",
    "    num_data = len(input_data)\n",
    "    num_param = len(input_data[0])\n",
    "    num_test = len(test_data)\n",
    "    print('number of data: ', num_data)\n",
    "    print('number of parameters: ', num_param)\n",
    "    print('number of test: ', num_test)\n",
    "    \n",
    "    num_batches = int(num_data/batch_size)\n",
    "    test_batches = int(num_test/batch_size)\n",
    "    input_param = np.array(input_data)\n",
    "    input_vol = np.array(input_vol)\n",
    "    test_param = np.array(test_data)\n",
    "    test_vol = np.array(test_vol)\n",
    "    \n",
    "    #y = fl_linear(input_param)\n",
    "    y, cost_op, input_parameter, input_volume = mat_mul(input_param, batch_size, num_param)\n",
    "    \n",
    "    learning_rate = tf.Variable(0.5, trainable=False)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost_op)\n",
    "    \n",
    "    sess = tf.Session() # Create TensorFlow session\n",
    "    print (\"Beginning Training\")\n",
    "    with sess.as_default():\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        sess.run(tf.assign(learning_rate, alpha))\n",
    "        for epoch in range(1, max_epochs):\n",
    "            print('epoch: ', epoch)\n",
    "            # Train one epoch\n",
    "            train_one_epoch(sess, cost_op, train_op, num_batches, input_parameter, input_param, input_volume, input_vol)\n",
    "            eval_one_epoch(sess, cost_op, test_batches, input_parameter, test_param, input_volume, test_vol)\n",
    "            \n",
    "\n",
    "def train_one_epoch(sess, cost_op, train_op, num_batches, input_parameter, input_param, input_volume, input_vol):\n",
    "     for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = (batch_idx+1) * batch_size\n",
    "        cost,_ = sess.run([cost_op, train_op], feed_dict={input_parameter: input_param[start_idx:end_idx], input_volume: input_vol[start_idx:end_idx]})\n",
    "        print(\"loss: \", cost)\n",
    "        \n",
    "def eval_one_epoch(sess, cost_op, test_batches, input_parameter, test_param, input_volume, test_vol):\n",
    "    for batch_idx in range(test_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = (batch_idx+1) * batch_size\n",
    "        cost = sess.run(cost_op, feed_dict={input_parameter: test_param[start_idx:end_idx], input_volume: test_vol[start_idx:end_idx]})\n",
    "        print(\"test loss: \", cost)\n",
    "\n",
    "# Parameters:\n",
    "last_cost = 0\n",
    "alpha = 0.4\n",
    "batch_size = 10\n",
    "max_epochs = 50000\n",
    "tolerance = 1e-3\n",
    "\n",
    "    \n",
    "train_path = '/home/carnd/CYML/output/train/cylinder/tri_1_to_50_2.txt'\n",
    "train_data, train_vol = load_input(train_path)\n",
    "print ('sample data: ', train_data[0])\n",
    "train(train_data, train_vol)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
