{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input: parametrized heights\n",
    "# Output: volume\n",
    "\n",
    "def placeholder_inputs(batch_size, num_param):\n",
    "    param_pl = tf.placeholder(name=\"input_param\", dtype=tf.float32, shape=(batch_size, num_param))\n",
    "    vol_pl = tf.placeholder(name=\"input_vol\", dtype=tf.float32, shape=(batch_size))\n",
    "    \n",
    "    return param_pl, vol_pl\n",
    "\n",
    "def load_input(train_path):\n",
    "    train = open(train_path, 'r')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for line in train:\n",
    "        data = eval(line)\n",
    "        if data[1] > 0:\n",
    "            train_x.append(data[0])\n",
    "            inv_vol = 1/data[1]\n",
    "            train_y.append(inv_vol)\n",
    "    print ('Number of data: ', len(train_x))\n",
    "    \n",
    "    return train_x, train_y\n",
    "\n",
    "def fl_linear(param, batch_size, num_param):\n",
    "    with tf.variable_scope(\"fl_linear\", reuse=True):\n",
    "        input_param = tf.placeholder(name=\"input_param\", dtype=tf.float32, shape=(batch_size, num_param))\n",
    "        input_vol = tf.placeholder(name=\"input_vol\", dtype=tf.float32, shape=(batch_size))\n",
    "        # Linear activation\n",
    "        net = tf.fully_connected(1, activation_fn=None, scope='fc1')\n",
    "    \n",
    "    return net\n",
    "\n",
    "def mat_mul(param, batch_size, num_param):\n",
    "    with tf.variable_scope(\"mat_mul\", reuse=True):\n",
    "        input_parameter = tf.placeholder(name=\"input_parameter\", dtype=tf.float32, shape=(batch_size, num_param))\n",
    "        input_volume = tf.placeholder(name=\"input_volume\", dtype=tf.float32, shape=(batch_size))\n",
    "        W = tf.Variable(tf.random_normal([num_param, 1], dtype=tf.float32), name=\"W\")\n",
    "        b = tf.Variable(tf.zeros([batch_size, 1], dtype=tf.float32), name=\"b\")\n",
    "        y = tf.add(tf.matmul(input_parameter, W), b)\n",
    "        cost_op = tf.reduce_mean(tf.pow(y-input_volume, 2))\n",
    "\n",
    "    return y, cost_op, input_parameter, input_volume\n",
    "\n",
    "def train(data, vol):\n",
    "    \n",
    "    input_data = data[0:1000]\n",
    "    input_vol = vol[0:1000]\n",
    "    \n",
    "    test_data = data[1000:2000]\n",
    "    test_vol = vol[1000:2000]\n",
    "    \n",
    "    num_data = len(input_data)\n",
    "    num_param = len(input_data[0])\n",
    "    num_test = len(test_data)\n",
    "    print('number of data: ', num_data)\n",
    "    print('number of parameters: ', num_param)\n",
    "    print('number of test: ', num_test)\n",
    "    \n",
    "    num_batches = int(num_data/batch_size)\n",
    "    test_batches = int(num_test/batch_size)\n",
    "    input_param = np.array(input_data)\n",
    "    input_vol = np.array(input_vol)\n",
    "    test_param = np.array(test_data)\n",
    "    test_vol = np.array(test_vol)\n",
    "    \n",
    "    #y = fl_linear(input_param)\n",
    "    y, cost_op, input_parameter, input_volume = mat_mul(input_param, batch_size, num_param)\n",
    "    \n",
    "    learning_rate = tf.Variable(0.5, trainable=False)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost_op)\n",
    "    \n",
    "    sess = tf.Session() # Create TensorFlow session\n",
    "    print (\"Beginning Training\")\n",
    "    with sess.as_default():\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        sess.run(tf.assign(learning_rate, alpha))\n",
    "        for epoch in range(1, max_epochs):\n",
    "            print('epoch: ', epoch)\n",
    "            # Train one epoch\n",
    "            train_one_epoch(sess, cost_op, train_op, num_batches, input_parameter, input_param, input_volume, input_vol)\n",
    "            eval_one_epoch(sess, cost_op, test_batches, input_parameter, test_param, input_volume, test_vol)\n",
    "            \n",
    "        print('Done.')\n",
    "        W = tf.get_variable(\"W\")\n",
    "        print(\"Weight: \", W.eval())\n",
    "            \n",
    "\n",
    "def train_one_epoch(sess, cost_op, train_op, num_batches, input_parameter, input_param, input_volume, input_vol):\n",
    "     for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = (batch_idx+1) * batch_size\n",
    "        cost,_ = sess.run([cost_op, train_op], feed_dict={input_parameter: input_param[start_idx:end_idx], input_volume: input_vol[start_idx:end_idx]})\n",
    "        print(\"loss: \", cost)\n",
    "        \n",
    "def eval_one_epoch(sess, cost_op, test_batches, input_parameter, test_param, input_volume, test_vol):\n",
    "    for batch_idx in range(test_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = (batch_idx+1) * batch_size\n",
    "        cost = sess.run(cost_op, feed_dict={input_parameter: test_param[start_idx:end_idx], input_volume: test_vol[start_idx:end_idx]})\n",
    "        print(\"test loss: \", cost)\n",
    "\n",
    "# Parameters:\n",
    "# last_cost = 0\n",
    "# alpha = 0.4\n",
    "# batch_size = 10\n",
    "# max_epochs = 100\n",
    "# tolerance = 1e-3\n",
    "\n",
    "    \n",
    "# train_path = '/home/carnd/CYML/output/train/cylinder/tri_1_to_50_2.txt'\n",
    "# train_data, train_vol = load_input(train_path)\n",
    "# print ('sample data: ', train_data[0])\n",
    "# train(train_data, train_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_5:0\", shape=(3,), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 1 but is rank 2 for 'concat_5' (op: 'ConcatV2') with input shapes: [3], [1,3], [].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 1 but is rank 2 for 'concat_5' (op: 'ConcatV2') with input shapes: [3], [1,3], [].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bf4441b23628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_param\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               tensor_shape.scalar())\n\u001b[1;32m   1188\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0m_attr_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m--> 953\u001b[0;31m         \"ConcatV2\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[1;32m    954\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1734\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1735\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 1 but is rank 2 for 'concat_5' (op: 'ConcatV2') with input shapes: [3], [1,3], []."
     ]
    }
   ],
   "source": [
    "data = np.arange(6).reshape(2,3)\n",
    "param = np.array([1,1,1])\n",
    "input_data = tf.placeholder(name=\"input_data\", dtype=tf.float32, shape=(2, 3))\n",
    "input_param = tf.placeholder(name=\"input_param\", dtype=tf.float32, shape=(1,3))\n",
    "for i in range(2):\n",
    "    row = input_data[i,]\n",
    "    print(row)\n",
    "    tmp = tf.concat([row, input_param], 1)\n",
    "    try:\n",
    "        out = tf.stack([input_param, tmp])\n",
    "    except:\n",
    "        out = tmp\n",
    "        \n",
    "sess = tf.Session() # Create TensorFlow session\n",
    "saver = tf.train.Saver()\n",
    "with sess.as_default():\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(\"slice: \", sess.run(row, feed_dict = {input_data:data, input_param:param}))\n",
    "    print(\"stack result: \", sess.run(out, feed_dict = {input_data:data, input_param:param}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_12:0\", shape=(2, 3), dtype=int32)\n",
      "Tensor(\"Reshape_14:0\", shape=(1, 3), dtype=int32)\n",
      "[[1, 2, 3]]\n",
      "Tensor(\"concat_12:0\", shape=(1, 6), dtype=int32)\n",
      "[[1, 2, 3, 8, 9, 10]]\n",
      "Tensor(\"MatMul_4:0\", shape=(3, 3), dtype=int32)\n",
      "[[1 2 3]\n",
      " [2 4 6]\n",
      " [3 6 9]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "x = tf.constant([[1,2,3],[8,9,10]])\n",
    "print(x)\n",
    "#y = tf.transpose(x[0,:])\n",
    "x_0 = x[0,:]\n",
    "x_0 = tf.reshape(x_0,[1,-1])\n",
    "x_1 = x[1,:]\n",
    "x_1 = tf.reshape(x_1,[1,-1])\n",
    "print(x_0)\n",
    "print(x_0.eval(session=sess).tolist())\n",
    "z = tf.concat([x_0,x_1],1)\n",
    "print(z)\n",
    "print(z.eval(session=sess).tolist())\n",
    "mul = tf.matmul(tf.transpose(x_0), x_0)\n",
    "print(mul)\n",
    "print(mul.eval(session=sess))\n",
    "for i in range(3):\n",
    "    concat = tf.reshape(mul[i,i:],[1,-1])\n",
    "    mul_tmp = tf.reshape(mul[i,i:],[1,-1])\n",
    "    concat = tf.concat([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_3:  [[1 2 3]\n",
      " [2 4 6]\n",
      " [3 6 9]]\n",
      "param_new reshaped 2:  Tensor(\"Reshape_1826:0\", shape=(6,), dtype=int32)\n",
      "param list:  Tensor(\"Reshape_1809:0\", shape=(1, 3), dtype=int32)\n",
      "x_3:  [[ 1  2  3]\n",
      " [ 2  4  6]\n",
      " [ 3  6  9]\n",
      " [ 4  8 12]\n",
      " [ 6 12 18]\n",
      " [ 9 18 27]]\n",
      "added row:  Tensor(\"Reshape_1842:0\", shape=(3,), dtype=int32)\n",
      "param_new:  Tensor(\"Reshape_1841:0\", shape=(1, 6), dtype=int32)\n",
      "param_new:  [[ 1  2  3  4  6  9  4  8 12]]\n",
      "param_new reshaped 2:  Tensor(\"Reshape_1844:0\", shape=(9,), dtype=int32)\n",
      "param list:  Tensor(\"concat_765:0\", shape=(1, 9), dtype=int32)\n",
      "param_fin:\n",
      "  [[ 1  2  3  1  2  3  4  6  9  1  2  3  4  6  9  4  8 12]]\n",
      "x_3:  [[49 56 63]\n",
      " [56 64 72]\n",
      " [63 72 81]]\n",
      "param_new reshaped 2:  Tensor(\"Reshape_1865:0\", shape=(6,), dtype=int32)\n",
      "param list:  Tensor(\"Reshape_1848:0\", shape=(1, 3), dtype=int32)\n",
      "x_3:  [[343 392 441]\n",
      " [392 448 504]\n",
      " [441 504 567]\n",
      " [448 512 576]\n",
      " [504 576 648]\n",
      " [567 648 729]]\n",
      "added row:  Tensor(\"Reshape_1881:0\", shape=(3,), dtype=int32)\n",
      "param_new:  Tensor(\"Reshape_1880:0\", shape=(1, 6), dtype=int32)\n",
      "param_new:  [[343 392 441 448 504 567 448 512 576]]\n",
      "param_new reshaped 2:  Tensor(\"Reshape_1883:0\", shape=(9,), dtype=int32)\n",
      "param list:  Tensor(\"concat_781:0\", shape=(1, 9), dtype=int32)\n",
      "param_fin:\n",
      "  [[  1   2   3   1   2   3   4   6   9   1   2   3   4   6   9   4   8  12]\n",
      " [  7   8   9  49  56  63  64  72  81 343 392 441 448 504 567 448 512 576]]\n"
     ]
    }
   ],
   "source": [
    "sess= tf.Session()\n",
    "degree = 2\n",
    "x = tf.constant([[1,2,3],[7,8,9]])\n",
    "num_batches = 2\n",
    "num_param = 3\n",
    "param_fin = tf.constant([])\n",
    "\n",
    "for i in range(num_batches):\n",
    "    num_row = num_param\n",
    "    x_0 = x[i, :]\n",
    "    param_list = tf.reshape(x_0, [1, -1])\n",
    "#     print ('param_list', param_list.eval(session=sess))\n",
    "    x_1 = tf.reshape(x_0, [-1, 1])\n",
    "#     print ('x_1: ', x_1.eval(session=sess))\n",
    "    \n",
    "    x_2 = tf.reshape(x_1, [1, -1])\n",
    "    \n",
    "    for deg in range(1, degree+1):\n",
    "        x_3 = tf.matmul(x_1, x_2)\n",
    "        print ('x_3: ', x_3.eval(session=sess))\n",
    "        param_new = tf.constant([])\n",
    "#         param_new[num_row] = x_3[num_row, num_row\n",
    "        counter = 0\n",
    "        for j in range(num_param):\n",
    "            for k in range(num_param):\n",
    "                if k >= j:\n",
    "                    diag = x_3[j,k]\n",
    "                    diag = tf.reshape(diag, [-1])\n",
    "                    counter += 1\n",
    "                    try:\n",
    "                        param_new = tf.concat([param_new, diag[None, :]], 0)\n",
    "                    except:\n",
    "                        param_new = tf.reshape(diag, [-1, 1])\n",
    "#                     print('counter: ', counter)\n",
    "#                     print('param_new: ', param_new.eval(session=sess))\n",
    "                    param_new = tf.reshape(param_new, [counter, -1])\n",
    "        #             print ('concating: ', param_new.eval(session=sess))\n",
    "#         diag = x_3[num_row-1,num_param-1]\n",
    "        param_new = tf.reshape(param_new, [1, -1])\n",
    "#         print ('param_new: ', param_new.eval(session=sess))\n",
    "        for j in range(num_param, num_row):\n",
    "            diag = x_3[j,:]\n",
    "            diag = tf.reshape(diag, [-1])\n",
    "            print('added row: ', diag)\n",
    "            print('param_new: ', param_new)\n",
    "            param_new = tf.concat([param_new, diag[None, :]], 1)\n",
    "            print('param_new: ', param_new.eval(session=sess))\n",
    "            counter += num_param\n",
    "            param_new = tf.reshape(param_new, [counter, -1])\n",
    "#             for k in range(num_param):\n",
    "#                 diag = x_3[j,k]\n",
    "#                 diag = tf.reshape(diag, [-1])\n",
    "#                 print('diag')\n",
    "#                 counter += 1\n",
    "#                 param_new = tf.concat([param_new, diag[None, :]], 0)\n",
    "#                 param_new = tf.reshape(param_new, [counter, -1])\n",
    "#         diag = tf.reshape(diag, [-1])\n",
    "#         print('last: ', diag.eval(session=sess))\n",
    "#         param_new = tf.concat([param_new, diag[None, :]], 0)\n",
    "#         print ('param_new: ', param_new.eval(session=sess))\n",
    "        param_new = tf.reshape(param_new, [-1])\n",
    "        print ('param_new reshaped 2: ', param_new)\n",
    "        print ('param list: ', param_list)\n",
    "        param_list = tf.concat([param_list, param_new[None,:]], 1)\n",
    "        x_1 = tf.reshape(param_new, [-1, 1])\n",
    "#         print ('x_1: ', x_1.eval(session=sess))\n",
    "        num_row += 1\n",
    "        \n",
    "    try:\n",
    "        param_list = tf.reshape(param_list, [-1])\n",
    "        param_fin = tf.concat([param_fin, param_list[None, :]], 0)\n",
    "    except:\n",
    "        param_fin = tf.reshape(param_list, [1, -1])\n",
    "    print ('param_fin:\\n ', param_fin.eval(session=sess))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "[[  0.   1.   2.   0.   0.   0.   1.   2.   4.]\n",
      " [  3.   4.   5.   9.  12.  15.  16.  20.  25.]\n",
      " [  6.   7.   8.  36.  42.  48.  49.  56.  64.]\n",
      " [  9.  10.  11.  81.  90.  99. 100. 110. 121.]\n",
      " [ 12.  13.  14. 144. 156. 168. 169. 182. 196.]\n",
      " [ 15.  16.  17. 225. 240. 255. 256. 272. 289.]]\n",
      "[6 9]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "print('Done.')\n",
    "\n",
    "def expand_2(input_param_1, batch_size, num_param):\n",
    "    for row in range(batch_size):\n",
    "        param_tmp = input_param_1[row,:]\n",
    "        param_tmp = tf.reshape(param_tmp, [1, -1])\n",
    "        param_mat = tf.matmul(tf.transpose(param_tmp),param_tmp)\n",
    "\n",
    "        for i in range(num_param):\n",
    "            param_tmp2 = tf.reshape(param_mat[i,i:], [1,-1])\n",
    "            #print(param_tmp2.eval(session=sess))\n",
    "            param_tmp = tf.concat([param_tmp,param_tmp2], 1)\n",
    "        param_tmp = tf.reshape(param_tmp, [-1])\n",
    "\n",
    "        try:\n",
    "            input_parameter = tf.concat([input_parameter,param_tmp[None, :]],0)\n",
    "            input_parameter = tf.reshape(input_parameter, [row+1, -1])\n",
    "        except:\n",
    "            input_parameter = param_tmp\n",
    "            input_parameter = tf.reshape(input_parameter, [row+1, -1])\n",
    "    \n",
    "    return input_parameter\n",
    "\n",
    "sess = tf.Session()\n",
    "data = np.arange(18)\n",
    "data = data.reshape([6,-1])\n",
    "batch_size = 6\n",
    "num_param = 3\n",
    "input_param_1 = tf.constant(data, dtype=tf.float32)\n",
    "input_parameter = expand_2(input_param_1, batch_size, num_param)\n",
    "\n",
    "# for row in range(batch_size):\n",
    "#     param_tmp = input_param_1[row,:]\n",
    "#     param_tmp = tf.reshape(param_tmp, [1, -1])\n",
    "#     param_mat = tf.matmul(tf.transpose(param_tmp),param_tmp)\n",
    "\n",
    "#     for i in range(num_param):\n",
    "#         param_tmp2 = tf.reshape(param_mat[i,i:], [1,-1])\n",
    "#         #print(param_tmp2.eval(session=sess))\n",
    "#         param_tmp = tf.concat([param_tmp,param_tmp2], 1)\n",
    "#     param_tmp = tf.reshape(param_tmp, [-1])\n",
    "\n",
    "#     try:\n",
    "#         input_parameter = tf.concat([input_parameter,param_tmp[None, :]],0)\n",
    "#         input_parameter = tf.reshape(input_parameter, [row+1, -1])\n",
    "#     except:\n",
    "#         input_parameter = param_tmp\n",
    "#         input_parameter = tf.reshape(input_parameter, [row+1, -1])\n",
    "\n",
    "print(input_parameter.eval(session=sess))\n",
    "print(tf.shape(input_parameter).eval(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_input(train_path):\n",
    "    train = open(train_path, 'r')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    counter = 0\n",
    "    for line in train:\n",
    "        if counter > 10:\n",
    "            break\n",
    "        data = eval(line)\n",
    "        if data[1] > 0:\n",
    "            train_x.append(data[0])\n",
    "#             inv_vol = 1/data[1]\n",
    "            train_y.append(data[1])\n",
    "        counter += 1\n",
    "    print ('Number of data: ', len(train_x))\n",
    "    \n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  -35.0043392\n",
      "Number of data:  11\n",
      "diff 0.5022808532687777\n",
      "diff 0.5022808532542258\n",
      "diff 0.327472965164726\n",
      "diff 0.5022808533524512\n",
      "diff 0.32747296516472557\n",
      "diff 0.2494767435816346\n",
      "diff 0.23791506801962586\n",
      "diff 0.5022808532396739\n",
      "diff 0.3274729651647258\n",
      "diff 0.24947674356162572\n",
      "diff 0.23791506801962442\n"
     ]
    }
   ],
   "source": [
    "W = np.array([-0.87437505,\n",
    "             6.952491,\n",
    "              4.5137253,\n",
    "              0.74184924,\n",
    "              2.0514772 ,\n",
    "             -0.14970087,\n",
    "             -0.13637641,\n",
    "             -0.20277256,\n",
    "             -0.05430971])\n",
    "b = np.array([-35.561787,\n",
    "             -35.39475 ,\n",
    "             -35.3224  ,\n",
    "             -34.635918,\n",
    "             -34.72557 ,\n",
    "             -34.767803,\n",
    "             -34.995155,\n",
    "             -34.83515 ,\n",
    "             -34.908066,\n",
    "             -34.896793])\n",
    "W = np.array([-1.32813477e+03,\n",
    "              2.83764465e+02,\n",
    "              5.81152466e+02,\n",
    "              1.65513077e+02,\n",
    "              1.64283314e+01,\n",
    "             -1.20188210e+02,\n",
    "              1.55702343e+01,\n",
    "              1.09391075e+02,\n",
    "             -1.57943008e+02,\n",
    "             -4.78923941e+00,\n",
    "             -2.92627001e+00,\n",
    "              1.90355957e+00,\n",
    "             -5.39966488e+00,\n",
    "             -4.67496252e+00,\n",
    "              1.12794566e+00,\n",
    "              7.61268473e+00,\n",
    "              1.16817160e+01,\n",
    "              6.08279085e+00,\n",
    "             -1.99237764e+00])\n",
    "b = np.array([-811.7567 \n",
    "             -751.0992 ,\n",
    "             -827.5288 ,\n",
    "             -879.7452 ,\n",
    "             -963.4682 ,\n",
    "             -740.0352 ,\n",
    "             -635.4922 ,\n",
    "             -712.0758 ,\n",
    "             -713.21295,\n",
    "             -757.816  ])\n",
    "\n",
    "# Mean:\n",
    "b_mean = np.mean(b)\n",
    "print('mean: ', b_mean)\n",
    "\n",
    "# Test if this model actually works\n",
    "train_path = '/home/carnd/CYML/output/train/cylinder/lift_1_to_50.txt'\n",
    "train_data, train_vol = load_input(train_path)\n",
    "num_data = len(train_data)\n",
    "num_param = len(train_data[0])\n",
    "# transform the num_data\n",
    "\n",
    "for i in range(num_data):\n",
    "    data = np.array(train_data[i])\n",
    "    data = np.expand_dims(data, axis=1)\n",
    "#     print('original: ', data)\n",
    "    data2 = data.reshape([num_param]).tolist()\n",
    "#     print('reshaped: ',data2)\n",
    "    data = np.matmul(data, np.transpose(data))\n",
    "#     print('matrix: ', data)\n",
    "    for j in range(num_param):\n",
    "        # for each row of this matrix\n",
    "        data2 += data[j,j:].tolist()\n",
    "        #data2.append(data[j,j:].tolist())\n",
    "#     print('extended data: ', data2)\n",
    "    pred = np.dot(data2, W)\n",
    "    diff = abs(1/float(pred) - train_vol[i])\n",
    "    print('diff', diff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data:  10\n",
      "train_data:  [[1, 0, 0], [1, 1, 0], [2, 0, 0], [1, 1, 1], [2, 1, 0], [3, 0, 0], [2, 1, 1], [2, 2, 0], [3, 1, 0], [4, 0, 0]]\n",
      "train_vol:  [1.6874999999416787, 2.3703703703703702, 3.3749999998833573, 2.8854381997703142, 2.4816806884647713, 5.06249999966964, 4.417092671887906, 4.740740740300995, 2.5292143561705105, 6.749999999352326]\n",
      "y:  [[-2033.21429352]\n",
      " [-1724.64925205]\n",
      " [-2898.33450839]\n",
      " [-1291.62351806]\n",
      " [-2589.2702816 ]\n",
      " [-3489.89944218]\n",
      " [-2055.25805308]\n",
      " [-2260.39522943]\n",
      " [-3191.13535983]\n",
      " [-3836.64453135]]\n",
      "train_vol:  [1.6875     2.37037037 3.375      2.8854382  2.48168069 5.0625\n",
      " 4.41709267 4.74074074 2.52921436 6.75      ]\n",
      "cost:  7048172.7598907305\n",
      "W:  [[-1.32813477e+03]\n",
      " [ 2.83764465e+02]\n",
      " [ 5.81152466e+02]\n",
      " [ 1.65513077e+02]\n",
      " [ 1.64283314e+01]\n",
      " [-1.20188210e+02]\n",
      " [ 1.55702343e+01]\n",
      " [ 1.09391075e+02]\n",
      " [-1.57943008e+02]\n",
      " [-4.78923941e+00]\n",
      " [-2.92627001e+00]\n",
      " [ 1.90355957e+00]\n",
      " [-5.39966488e+00]\n",
      " [-4.67496252e+00]\n",
      " [ 1.12794566e+00]\n",
      " [ 7.61268473e+00]\n",
      " [ 1.16817160e+01]\n",
      " [ 6.08279085e+00]\n",
      " [-1.99237764e+00]]\n",
      "diff:  [0.59308442]\n",
      "diff:  [0.42245483]\n",
      "diff:  [0.29664132]\n",
      "diff:  [0.34734203]\n",
      "diff:  [0.40333894]\n",
      "diff:  [0.19781741]\n",
      "diff:  [0.22687981]\n",
      "diff:  [0.2113799]\n",
      "diff:  [0.39569306]\n",
      "diff:  [0.14840879]\n"
     ]
    }
   ],
   "source": [
    "def load_input(train_path):\n",
    "    train = open(train_path, 'r')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    counter = 0\n",
    "    for line in train:\n",
    "        if counter >= 10:\n",
    "            break\n",
    "        data = eval(line)\n",
    "        if data[1] > 0:\n",
    "            train_x.append(data[0])\n",
    "            inv_vol = 1/data[1]\n",
    "            train_y.append(inv_vol)\n",
    "        counter += 1\n",
    "    print ('Number of data: ', len(train_x))\n",
    "    \n",
    "    return train_x, train_y\n",
    "\n",
    "def expand_3(input_param_1, W, b_m, train_vol):\n",
    "    # TODO: make this more general\n",
    "    num_param = 3\n",
    "    input_param = 10\n",
    "    for row in range(batch_size):\n",
    "        param_tmp = input_param_1[row,:]\n",
    "        param_tmp = tf.reshape(param_tmp, [1, -1])\n",
    "        p1 = param_tmp[0,0]\n",
    "        p2 = param_tmp[0,1]\n",
    "        p3 = param_tmp[0,2]\n",
    "        \n",
    "        p = tf.pow(p1,2)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.pow(p2,2)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.pow(p3,2)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        \n",
    "        p = tf.multiply(p1, p2)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.multiply(p1, p3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.multiply(p2, p3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        \n",
    "        p = tf.pow(p1,3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.pow(p2,3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.pow(p3,3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        \n",
    "        p = tf.multiply(tf.pow(p1,2), p2)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.multiply(tf.pow(p1,2), p3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.multiply(p1, tf.pow(p2,2))\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.multiply(p1, tf.pow(p3,2))\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        \n",
    "        p = tf.multiply(tf.pow(p2,2), p3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.multiply(tf.pow(p3,2), p2)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        \n",
    "        p = tf.multiply(tf.multiply(p1, p2),p3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        param_tmp = tf.cast(param_tmp, tf.float64)\n",
    "        \n",
    "        try:\n",
    "            param_tmp = tf.reshape(param_tmp, [-1])\n",
    "            input_param = tf.concat([input_param, param_tmp[None,:]], 0)\n",
    "        except:\n",
    "            input_param = tf.reshape(param_tmp, [1, -1])\n",
    "    \n",
    "    W = tf.constant(W)\n",
    "    W = tf.reshape(W, [-1,1])\n",
    "    W = tf.cast(W, tf.float64)\n",
    "    b_m = tf.constant(b_m)\n",
    "    b_m = tf.cast(b_m, tf.float64)\n",
    "    y = tf.add(tf.matmul(input_param, W), b_m)\n",
    "    train_vol = tf.constant(train_vol, dtype=tf.float64)\n",
    "    train_vol = tf.cast(train_vol, tf.float64)\n",
    "    print('y: ', y.eval(session=sess))\n",
    "    print('train_vol: ', train_vol.eval(session=sess))\n",
    "#     cost = tf.reduce_mean(tf.pow(y-tf.multiply(train_vol, y),2))\n",
    "    cost = tf.reduce_mean(tf.pow(y-train_vol,2))\n",
    "    num_param = num_param + 6+ 10\n",
    "    return input_param, cost\n",
    "\n",
    "W = np.array([-1.32813477e+03,\n",
    "              2.83764465e+02,\n",
    "              5.81152466e+02,\n",
    "              1.65513077e+02,\n",
    "              1.64283314e+01,\n",
    "             -1.20188210e+02,\n",
    "              1.55702343e+01,\n",
    "              1.09391075e+02,\n",
    "             -1.57943008e+02,\n",
    "             -4.78923941e+00,\n",
    "             -2.92627001e+00,\n",
    "              1.90355957e+00,\n",
    "             -5.39966488e+00,\n",
    "             -4.67496252e+00,\n",
    "              1.12794566e+00,\n",
    "              7.61268473e+00,\n",
    "              1.16817160e+01,\n",
    "              6.08279085e+00,\n",
    "             -1.99237764e+00])\n",
    "b = np.array([-811.7567 \n",
    "             -751.0992 ,\n",
    "             -827.5288 ,\n",
    "             -879.7452 ,\n",
    "             -963.4682 ,\n",
    "             -740.0352 ,\n",
    "             -635.4922 ,\n",
    "             -712.0758 ,\n",
    "             -713.21295,\n",
    "             -757.816  ])\n",
    "\n",
    "sess = tf.Session()\n",
    "train_path = '/home/carnd/CYML/output/train/cylinder/lift_1_to_50.txt'\n",
    "train_data, train_vol = load_input(train_path)\n",
    "print('train_data: ', train_data)\n",
    "print('train_vol: ', train_vol)\n",
    "input_data = tf.constant(train_data)\n",
    "b = b.reshape([-1,1])\n",
    "b_mean = np.mean(b)\n",
    "input_param, cost = expand_3(input_data, W, b_mean, train_vol)\n",
    "print('cost: ', cost.eval(session=sess))\n",
    "input_data = input_param.eval(session=sess)\n",
    "# print('input_param: ', input_data)\n",
    "W = W.reshape([-1,1])\n",
    "print('W: ', W)\n",
    "pred_list = np.dot(input_data, W)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for row in range(pred_list.shape[0]):\n",
    "    pred = 1/(pred_list[row]+b_mean)\n",
    "    diff = abs(1/train_vol[row] - pred)\n",
    "    print ('diff: ', diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mat_mul(param, batch_size, num_param, deg):\n",
    "    # Hyper-parmeter: how many layers we will need\n",
    "    with tf.variable_scope(\"mat_mul\", reuse=True):\n",
    "        input_param_1 = tf.placeholder(name=\"input_param_1\", dtype=tf.float32, shape=(batch_size, num_param))\n",
    "        input_volume = tf.placeholder(name=\"input_volume\", dtype=tf.float32, shape=(batch_size))\n",
    "        \n",
    "        for i in range(deg):\n",
    "            deg_n1 = tf.matmul(deg_n0, tf.transpose(deg_1))\n",
    "            deg_n2 = tf.concat([deg_n1, deg_1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        input_parameter = expand_2(input_param_1, batch_size, num_param)\n",
    "        num_param = int(num_param + num_param*(num_param+1)/2)\n",
    "\n",
    "        W1 = tf.Variable(tf.random_normal([num_param, 1], dtype=tf.float32), name=\"W\")\n",
    "        b1 = tf.Variable(tf.zeros([batch_size, 1], dtype=tf.float32), name=\"b\")\n",
    "        y = tf.add(tf.matmul(input_parameter, W1), b1)\n",
    "        \n",
    "        cost_op = tf.reduce_mean(tf.pow(y-input_volume, 2))\n",
    "    \n",
    "    return y, cost_op, input_param_1, input_volume, input_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_tmp: [[ 1  2  3  1  4  9  2  3  6  1  8 27  2  3  4  9 12 18  6]]\n",
      "init\n",
      "input_param: [[ 1  2  3  1  4  9  2  3  6  1  8 27  2  3  4  9 12 18  6]]\n",
      "param_tmp: [[   2    3   10    4    9  100    6   20   30    8   27 1000   12   40\n",
      "    18  200   90  300   60]]\n",
      "concat\n",
      "input_param: [[   1    2    3    1    4    9    2    3    6    1    8   27    2    3\n",
      "     4    9   12   18    6]\n",
      " [   2    3   10    4    9  100    6   20   30    8   27 1000   12   40\n",
      "    18  200   90  300   60]]\n",
      "num_param:  19\n"
     ]
    }
   ],
   "source": [
    "def expand_3(input_param_1, batch_size, num_param):\n",
    "    # TODO: make this more general\n",
    "    num_param = 3\n",
    "    input_param = 10\n",
    "    for row in range(batch_size):\n",
    "        param_tmp = input_param_1[row,:]\n",
    "        param_tmp = tf.reshape(param_tmp, [1, -1])\n",
    "        p1 = param_tmp[0,0]\n",
    "        p2 = param_tmp[0,1]\n",
    "        p3 = param_tmp[0,2]\n",
    "        \n",
    "        p = tf.pow(p1,2)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.pow(p2,2)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.pow(p3,2)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        \n",
    "        p = tf.multiply(p1, p2)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.multiply(p1, p3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.multiply(p2, p3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        \n",
    "        p = tf.pow(p1,3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.pow(p2,3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.pow(p3,3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        \n",
    "        p = tf.multiply(tf.pow(p1,2), p2)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.multiply(tf.pow(p1,2), p3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.multiply(p1, tf.pow(p2,2))\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.multiply(p1, tf.pow(p3,2))\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        \n",
    "        p = tf.multiply(tf.pow(p2,2), p3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        p = tf.multiply(tf.pow(p3,2), p2)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        \n",
    "        p = tf.multiply(tf.multiply(p1, p2),p3)\n",
    "        p = tf.reshape(p, [-1])\n",
    "        param_tmp = tf.concat([param_tmp, p[None,:]], 1)\n",
    "        \n",
    "        print('param_tmp:', param_tmp.eval(session=sess))\n",
    "        \n",
    "        try:\n",
    "            param_tmp = tf.reshape(param_tmp, [-1])\n",
    "            input_param = tf.concat([input_param, param_tmp[None,:]], 0)\n",
    "            print('concat')\n",
    "        except:\n",
    "            print('init')\n",
    "            input_param = tf.reshape(param_tmp, [1, -1])\n",
    "        print('input_param:',input_param.eval(session=sess))\n",
    "    \n",
    "    num_param = num_param + 6+ 10\n",
    "    return input_param, num_param\n",
    "\n",
    "sess = tf.Session()\n",
    "input_param = tf.constant([[1,2,3],[2,3,10]])\n",
    "input_param, num_param = expand_3(input_param, 2, 3)\n",
    "print ('num_param: ', num_param)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
