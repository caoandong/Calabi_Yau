{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data:  10100\n",
      "sample data:  [0, 1, 1]\n",
      "number of data:  1000\n",
      "number of parameters:  3\n",
      "number of test:  1000\n",
      "Beginning Training\n",
      "epoch:  1\n",
      "loss:  3.1031156\n",
      "loss:  7.9520044\n",
      "loss:  9.177099\n",
      "loss:  12.003052\n",
      "loss:  14.035508\n",
      "loss:  8.885265\n",
      "loss:  9.026624\n",
      "loss:  4.992687\n",
      "loss:  9.242185\n",
      "loss:  26.32302\n",
      "loss:  1.9487853\n",
      "loss:  6.0147943\n",
      "loss:  23.573664\n",
      "loss:  3.2422874\n",
      "loss:  7.05889\n",
      "loss:  4.739183\n",
      "loss:  10.82374\n",
      "loss:  3.471589\n",
      "loss:  7.0185413\n",
      "loss:  6.301442\n",
      "loss:  25.917585\n",
      "loss:  2.4931765\n",
      "loss:  5.97263\n",
      "loss:  15.561093\n",
      "loss:  12.069449\n",
      "loss:  20.573374\n",
      "loss:  3.9292612\n",
      "loss:  6.4307714\n",
      "loss:  8.255787\n",
      "loss:  4.9081564\n",
      "loss:  38.885517\n",
      "loss:  1.6573607\n",
      "loss:  2.7661383\n",
      "loss:  11.351982\n",
      "loss:  18.123781\n",
      "loss:  14.559143\n",
      "loss:  1.4899789\n",
      "loss:  42.973263\n",
      "loss:  7.304552\n",
      "loss:  10.019865\n",
      "loss:  8.877336\n",
      "loss:  3.2558935\n",
      "loss:  0.5282096\n",
      "loss:  5.084958\n",
      "loss:  53.775986\n",
      "loss:  1.5594122\n",
      "loss:  5.7328963\n",
      "loss:  11.339006\n",
      "loss:  9.561106\n",
      "loss:  4.8412266\n",
      "loss:  1.1080605\n",
      "loss:  8.437989\n",
      "loss:  98.00172\n",
      "loss:  5.919627\n",
      "loss:  1.6843587\n",
      "loss:  1.3752342\n",
      "loss:  6.3780613\n",
      "loss:  14.349873\n",
      "loss:  10.733508\n",
      "loss:  2.6129088\n",
      "loss:  3.0572872\n",
      "loss:  96.90554\n",
      "loss:  9.689693\n",
      "loss:  13.584476\n",
      "loss:  3.0645106\n",
      "loss:  1.6729659\n",
      "loss:  7.605645\n",
      "loss:  10.162215\n",
      "loss:  6.556885\n",
      "loss:  2.590607\n",
      "loss:  4.1125026\n",
      "loss:  108.51422\n",
      "loss:  8.167499\n",
      "loss:  3.833581\n",
      "loss:  1.5137916\n",
      "loss:  1.9994872\n",
      "loss:  7.58682\n",
      "loss:  9.128848\n",
      "loss:  4.730686\n",
      "loss:  1.2607151\n",
      "loss:  3.830061\n",
      "loss:  7.3771253\n",
      "loss:  123.803894\n",
      "loss:  4.682311\n",
      "loss:  0.91799426\n",
      "loss:  4.7891006\n",
      "loss:  14.993697\n",
      "loss:  23.297886\n",
      "loss:  16.230738\n",
      "loss:  3.2444851\n",
      "loss:  3.1623487\n",
      "loss:  15.834075\n",
      "loss:  17.85625\n",
      "loss:  6.8397617\n",
      "loss:  115.28604\n",
      "loss:  2.3118083\n",
      "loss:  3.5263014\n",
      "loss:  20.494429\n",
      "loss:  43.802906\n",
      "loss:  49.7538\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_param' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-05cbd698f2bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_vol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'sample data: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_vol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-05cbd698f2bc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, vol)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# Train one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_parameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_volume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_vol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0meval_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_parameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_volume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_vol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_param' is not defined"
     ]
    }
   ],
   "source": [
    "# Input: parametrized heights\n",
    "# Output: volume\n",
    "\n",
    "def placeholder_inputs(batch_size, num_param):\n",
    "    param_pl = tf.placeholder(name=\"input_param\", dtype=tf.float32, shape=(batch_size, num_param))\n",
    "    vol_pl = tf.placeholder(name=\"input_vol\", dtype=tf.float32, shape=(batch_size))\n",
    "    \n",
    "    return param_pl, vol_pl\n",
    "\n",
    "def load_input(train_path):\n",
    "    train = open(train_path, 'r')\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for line in train:\n",
    "        data = eval(line)\n",
    "        if data[1] > 0:\n",
    "            train_x.append(data[0])\n",
    "            inv_vol = 1/data[1]\n",
    "            train_y.append(inv_vol)\n",
    "    print ('Number of data: ', len(train_x))\n",
    "    \n",
    "    return train_x, train_y\n",
    "\n",
    "def fl_linear(param, batch_size, num_param):\n",
    "    with tf.variable_scope(\"fl_linear\", reuse=True):\n",
    "        input_param = tf.placeholder(name=\"input_param\", dtype=tf.float32, shape=(batch_size, num_param))\n",
    "        input_vol = tf.placeholder(name=\"input_vol\", dtype=tf.float32, shape=(batch_size))\n",
    "        # Linear activation\n",
    "        net = tf.fully_connected(1, activation_fn=None, scope='fc1')\n",
    "    \n",
    "    return net\n",
    "\n",
    "def mat_mul(param, batch_size, num_param):\n",
    "    with tf.variable_scope(\"mat_mul\", reuse=True):\n",
    "        input_parameter = tf.placeholder(name=\"input_parameter\", dtype=tf.float32, shape=(batch_size, num_param))\n",
    "        input_volume = tf.placeholder(name=\"input_volume\", dtype=tf.float32, shape=(batch_size))\n",
    "        W = tf.Variable(tf.random_normal([num_param, 1], dtype=tf.float32), name=\"W\")\n",
    "        b = tf.Variable(tf.zeros([batch_size, 1], dtype=tf.float32), name=\"b\")\n",
    "        y = tf.add(tf.matmul(input_parameter, W), b)\n",
    "        cost_op = tf.reduce_mean(tf.pow(y-input_volume, 2))\n",
    "\n",
    "    return y, cost_op, input_parameter, input_volume\n",
    "\n",
    "def train(data, vol):\n",
    "    \n",
    "    input_data = data[0:1000]\n",
    "    input_vol = vol[0:1000]\n",
    "    \n",
    "    test_data = data[1000:2000]\n",
    "    test_vol = vol[1000:2000]\n",
    "    \n",
    "    num_data = len(input_data)\n",
    "    num_param = len(input_data[0])\n",
    "    num_test = len(test_data)\n",
    "    print('number of data: ', num_data)\n",
    "    print('number of parameters: ', num_param)\n",
    "    print('number of test: ', num_test)\n",
    "    \n",
    "    num_batches = int(num_data/batch_size)\n",
    "    test_batches = int(num_test/batch_size)\n",
    "    input_param = np.array(input_data)\n",
    "    input_vol = np.array(input_vol)\n",
    "    test_param = np.array(test_data)\n",
    "    test_vol = np.array(test_vol)\n",
    "    \n",
    "    #y = fl_linear(input_param)\n",
    "    y, cost_op, input_parameter, input_volume = mat_mul(input_param, batch_size, num_param)\n",
    "    \n",
    "    learning_rate = tf.Variable(0.5, trainable=False)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost_op)\n",
    "    \n",
    "    sess = tf.Session() # Create TensorFlow session\n",
    "    print (\"Beginning Training\")\n",
    "    with sess.as_default():\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        sess.run(tf.assign(learning_rate, alpha))\n",
    "        for epoch in range(1, max_epochs):\n",
    "            print('epoch: ', epoch)\n",
    "            # Train one epoch\n",
    "            train_one_epoch(sess, cost_op, train_op, num_batches, input_parameter, input_param, input_volume, input_vol)\n",
    "            eval_one_epoch(sess, cost_op, test_batches, input_parameter, test_param, input_volume, test_vol)\n",
    "            \n",
    "        print('Done.')\n",
    "        W = tf.get_variable(\"W\")\n",
    "        print(\"Weight: \", W.eval())\n",
    "            \n",
    "\n",
    "def train_one_epoch(sess, cost_op, train_op, num_batches, input_parameter, input_param, input_volume, input_vol):\n",
    "     for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = (batch_idx+1) * batch_size\n",
    "        cost,_ = sess.run([cost_op, train_op], feed_dict={input_parameter: input_param[start_idx:end_idx], input_volume: input_vol[start_idx:end_idx]})\n",
    "        print(\"loss: \", cost)\n",
    "        \n",
    "def eval_one_epoch(sess, cost_op, test_batches, input_parameter, test_param, input_volume, test_vol):\n",
    "    for batch_idx in range(test_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = (batch_idx+1) * batch_size\n",
    "        cost = sess.run(cost_op, feed_dict={input_parameter: test_param[start_idx:end_idx], input_volume: test_vol[start_idx:end_idx]})\n",
    "        print(\"test loss: \", cost)\n",
    "\n",
    "# Parameters:\n",
    "last_cost = 0\n",
    "alpha = 0.4\n",
    "batch_size = 10\n",
    "max_epochs = 100\n",
    "tolerance = 1e-3\n",
    "\n",
    "    \n",
    "train_path = '/home/carnd/CYML/output/train/cylinder/tri_1_to_50_2.txt'\n",
    "train_data, train_vol = load_input(train_path)\n",
    "print ('sample data: ', train_data[0])\n",
    "train(train_data, train_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_5:0\", shape=(3,), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 1 but is rank 2 for 'concat_5' (op: 'ConcatV2') with input shapes: [3], [1,3], [].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 1 but is rank 2 for 'concat_5' (op: 'ConcatV2') with input shapes: [3], [1,3], [].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bf4441b23628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_param\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               tensor_shape.scalar())\n\u001b[1;32m   1188\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0m_attr_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m--> 953\u001b[0;31m         \"ConcatV2\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[1;32m    954\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1734\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1735\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 1 but is rank 2 for 'concat_5' (op: 'ConcatV2') with input shapes: [3], [1,3], []."
     ]
    }
   ],
   "source": [
    "data = np.arange(6).reshape(2,3)\n",
    "param = np.array([1,1,1])\n",
    "input_data = tf.placeholder(name=\"input_data\", dtype=tf.float32, shape=(2, 3))\n",
    "input_param = tf.placeholder(name=\"input_param\", dtype=tf.float32, shape=(1,3))\n",
    "for i in range(2):\n",
    "    row = input_data[i,]\n",
    "    print(row)\n",
    "    tmp = tf.concat([row, input_param], 1)\n",
    "    try:\n",
    "        out = tf.stack([input_param, tmp])\n",
    "    except:\n",
    "        out = tmp\n",
    "        \n",
    "sess = tf.Session() # Create TensorFlow session\n",
    "saver = tf.train.Saver()\n",
    "with sess.as_default():\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(\"slice: \", sess.run(row, feed_dict = {input_data:data, input_param:param}))\n",
    "    print(\"stack result: \", sess.run(out, feed_dict = {input_data:data, input_param:param}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_12:0\", shape=(2, 3), dtype=int32)\n",
      "Tensor(\"Reshape_14:0\", shape=(1, 3), dtype=int32)\n",
      "[[1, 2, 3]]\n",
      "Tensor(\"concat_12:0\", shape=(1, 6), dtype=int32)\n",
      "[[1, 2, 3, 8, 9, 10]]\n",
      "Tensor(\"MatMul_4:0\", shape=(3, 3), dtype=int32)\n",
      "[[1 2 3]\n",
      " [2 4 6]\n",
      " [3 6 9]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "x = tf.constant([[1,2,3],[8,9,10]])\n",
    "print(x)\n",
    "#y = tf.transpose(x[0,:])\n",
    "x_0 = x[0,:]\n",
    "x_0 = tf.reshape(x_0,[1,-1])\n",
    "x_1 = x[1,:]\n",
    "x_1 = tf.reshape(x_1,[1,-1])\n",
    "print(x_0)\n",
    "print(x_0.eval(session=sess).tolist())\n",
    "z = tf.concat([x_0,x_1],1)\n",
    "print(z)\n",
    "print(z.eval(session=sess).tolist())\n",
    "mul = tf.matmul(tf.transpose(x_0), x_0)\n",
    "print(mul)\n",
    "print(mul.eval(session=sess))\n",
    "for i in range(3):\n",
    "    concat = tf.reshape(mul[i,i:],[1,-1])\n",
    "    mul_tmp = tf.reshape(mul[i,i:],[1,-1])\n",
    "    concat = tf.concat([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "[[  0.   1.   2.   0.   0.   0.   1.   2.   4.]\n",
      " [  3.   4.   5.   9.  12.  15.  16.  20.  25.]\n",
      " [  6.   7.   8.  36.  42.  48.  49.  56.  64.]\n",
      " [  9.  10.  11.  81.  90.  99. 100. 110. 121.]\n",
      " [ 12.  13.  14. 144. 156. 168. 169. 182. 196.]\n",
      " [ 15.  16.  17. 225. 240. 255. 256. 272. 289.]]\n",
      "[6 9]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "print('Done.')\n",
    "\n",
    "def expand_2(input_param_1, batch_size, num_param):\n",
    "    for row in range(batch_size):\n",
    "        param_tmp = input_param_1[row,:]\n",
    "        param_tmp = tf.reshape(param_tmp, [1, -1])\n",
    "        param_mat = tf.matmul(tf.transpose(param_tmp),param_tmp)\n",
    "\n",
    "        for i in range(num_param):\n",
    "            param_tmp2 = tf.reshape(param_mat[i,i:], [1,-1])\n",
    "            #print(param_tmp2.eval(session=sess))\n",
    "            param_tmp = tf.concat([param_tmp,param_tmp2], 1)\n",
    "        param_tmp = tf.reshape(param_tmp, [-1])\n",
    "\n",
    "        try:\n",
    "            input_parameter = tf.concat([input_parameter,param_tmp[None, :]],0)\n",
    "            input_parameter = tf.reshape(input_parameter, [row+1, -1])\n",
    "        except:\n",
    "            input_parameter = param_tmp\n",
    "            input_parameter = tf.reshape(input_parameter, [row+1, -1])\n",
    "    \n",
    "    return input_parameter\n",
    "\n",
    "sess = tf.Session()\n",
    "data = np.arange(18)\n",
    "data = data.reshape([6,-1])\n",
    "batch_size = 6\n",
    "num_param = 3\n",
    "input_param_1 = tf.constant(data, dtype=tf.float32)\n",
    "input_parameter = expand_2(input_param_1, batch_size, num_param)\n",
    "\n",
    "# for row in range(batch_size):\n",
    "#     param_tmp = input_param_1[row,:]\n",
    "#     param_tmp = tf.reshape(param_tmp, [1, -1])\n",
    "#     param_mat = tf.matmul(tf.transpose(param_tmp),param_tmp)\n",
    "\n",
    "#     for i in range(num_param):\n",
    "#         param_tmp2 = tf.reshape(param_mat[i,i:], [1,-1])\n",
    "#         #print(param_tmp2.eval(session=sess))\n",
    "#         param_tmp = tf.concat([param_tmp,param_tmp2], 1)\n",
    "#     param_tmp = tf.reshape(param_tmp, [-1])\n",
    "\n",
    "#     try:\n",
    "#         input_parameter = tf.concat([input_parameter,param_tmp[None, :]],0)\n",
    "#         input_parameter = tf.reshape(input_parameter, [row+1, -1])\n",
    "#     except:\n",
    "#         input_parameter = param_tmp\n",
    "#         input_parameter = tf.reshape(input_parameter, [row+1, -1])\n",
    "\n",
    "print(input_parameter.eval(session=sess))\n",
    "print(tf.shape(input_parameter).eval(session=sess))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
