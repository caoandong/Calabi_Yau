{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = '/home/carnd/CYML/output/train/cube_337.txt'\n",
    "out_path = '/home/carnd/CYML/output/train/cube_3_35.txt'\n",
    "file = open(file_path, 'r')\n",
    "out = open(out_path, 'w')\n",
    "max_pts = 128\n",
    "for line in file:\n",
    "    l = eval(line)\n",
    "    pts_new = pts = l[0]\n",
    "    num_pts = len(pts)\n",
    "    if num_pts < max_pts:\n",
    "        for i in range(max_pts - num_pts):\n",
    "            pts_new.append([1j,1j,1j])\n",
    "    #print(pts_new)\n",
    "    if l[1] == -1:\n",
    "        continue\n",
    "    out.write(\"%s\\n\" % [pts_new, l[1]])\n",
    "out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = '/home/carnd/CYML/output/vol/vol_cube_5.txt'\n",
    "out_path = '/home/carnd/CYML/output/vol/vol_cube_5_35.txt'\n",
    "file = open(file_path, 'r')\n",
    "out = open(out_path, 'w')\n",
    "for line in file:\n",
    "    I = 1j\n",
    "    l = eval(line)\n",
    "    pts_new = []\n",
    "    pts = l[0]\n",
    "    if l[1] != -1:\n",
    "        for i in range(len(pts)):\n",
    "            pts_new.append(pts[i])\n",
    "            #if pts[i][0] != 1.00000000000000*I and pts[i][1] != 1.00000000000000*I and pts[i][2] != 1.00000000000000*I:\n",
    "            #    pts_new.append(pts[i])\n",
    "        out.write(\"%s\\n\" % [pts_new, l[1]])\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "file_path = '/home/carnd/CYML/output/vol/vol_cube_5_35.txt'\n",
    "file = open(file_path, 'r')\n",
    "max_pts = 0\n",
    "for line in file:\n",
    "    num_pts = len(eval(line)[0])\n",
    "    if num_pts > max_pts:\n",
    "        max_pts = num_pts\n",
    "print(max_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = '/home/carnd/CYML/output/vol/vol_cube_5_35.txt'\n",
    "out_path = '/home/carnd/CYML/output/train/train_cube_5_35.txt'\n",
    "file = open(file_path, 'r')\n",
    "out = open(out_path, 'w')\n",
    "max_num = 128\n",
    "for line in file:\n",
    "    l = eval(line)\n",
    "    pts_new = pts = l[0]\n",
    "    num_pts = len(pts)\n",
    "    if num_pts > max_pts:\n",
    "        continue\n",
    "    if num_pts < max_pts:\n",
    "        for i in range(max_pts - num_pts):\n",
    "            pts_new.append([1j,1j,1j])\n",
    "    if l[1] == -1:\n",
    "        continue\n",
    "    out.write(\"%s\\n\" % [pts_new, l[1]])\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import h5py\n",
    "import numpy as np\n",
    "import provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'provider' has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a4eed248066d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mrotated_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprovider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotated_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rotated data: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotated_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-a4eed248066d>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_FILES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#current_data, current_label = provider.loadDataFile(TRAIN_FILES[train_file_idxs[fn]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mcurrent_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprovider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_FILES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_file_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mcurrent_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprovider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcurrent_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'provider' has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "TRAIN_FILES_path = '/home/carnd/CYML/output/train/train_cube_5_35.txt'\n",
    "TRAIN_FILES_path = str(TRAIN_FILES_path)\n",
    "\n",
    "train_file = open(TRAIN_FILES_path, 'r')\n",
    "\n",
    "TRAIN_FILES = [ eval(line) for line in train_file]\n",
    "\n",
    "def train_one_epoch():\n",
    "    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n",
    "    is_training = True\n",
    "\n",
    "    # Shuffle train files\n",
    "    train_file_idxs = np.arange(0, len(TRAIN_FILES))\n",
    "    np.random.shuffle(train_file_idxs)\n",
    "\n",
    "    for fn in range(len(TRAIN_FILES)):\n",
    "        #current_data, current_label = provider.loadDataFile(TRAIN_FILES[train_file_idxs[fn]])\n",
    "        current_data, current_label = provider.load(TRAIN_FILES[train_file_idxs[fn]])\n",
    "        current_data, current_label, _ = provider.shuffle_data(current_data, np.squeeze(current_label))\n",
    "        current_label = np.squeeze(current_label)\n",
    "\n",
    "        file_size = len(current_data)\n",
    "        print(\"file size: \", file_size)\n",
    "        num_batches = math.floor(file_size // BATCH_SIZE)\n",
    "        print(\"num batches: \", num_batches)\n",
    "\n",
    "        current_data = np.array(current_data)\n",
    "        current_label = np.array(current_label)\n",
    "        print(\"current_data size: \", current_data.shape)\n",
    "\n",
    "        total_correct = 0\n",
    "        total_seen = 0\n",
    "        loss_sum = 0\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * BATCH_SIZE\n",
    "            end_idx = (batch_idx+1) * BATCH_SIZE\n",
    "\n",
    "            # Augment batched point clouds by rotation\n",
    "            rotated_data = provider.rotate_point_cloud(current_data[start_idx:end_idx])\n",
    "            rotated_data = provider.to_grid(rotated_data, 5)\n",
    "            print(\"rotated data: \", rotated_data)\n",
    "train_one_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1+0j)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(1j**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
